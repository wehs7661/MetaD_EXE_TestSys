                :-) GROMACS - gmx mdrun, 2021.4-plumed-2.8.0 (-:

                            GROMACS is written by:
     Andrey Alekseenko              Emile Apol              Rossen Apostolov     
         Paul Bauer           Herman J.C. Berendsen           Par Bjelkmar       
       Christian Blau           Viacheslav Bolnykh             Kevin Boyd        
     Aldert van Buuren           Rudi van Drunen             Anton Feenstra      
    Gilles Gouaillardet             Alan Gray               Gerrit Groenhof      
       Anca Hamuraru            Vincent Hindriksen          M. Eric Irrgang      
      Aleksei Iupinov           Christoph Junghans             Joe Jordan        
    Dimitrios Karkoulis            Peter Kasson                Jiri Kraus        
      Carsten Kutzner              Per Larsson              Justin A. Lemkul     
       Viveca Lindahl            Magnus Lundborg             Erik Marklund       
        Pascal Merz             Pieter Meulenhoff            Teemu Murtola       
        Szilard Pall               Sander Pronk              Roland Schulz       
       Michael Shirts            Alexey Shvetsov             Alfons Sijbers      
       Peter Tieleman              Jon Vincent              Teemu Virolainen     
     Christian Wennberg            Maarten Wolf              Artem Zhmurov       
                           and the project leaders:
        Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2019, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, version 2021.4-plumed-2.8.0
Executable:   /jet/home/wehs7661/pkgs/gromacs/2021.4/bin/gmx_mpi
Data prefix:  /jet/home/wehs7661/pkgs/gromacs/2021.4
Working dir:  /ocean/projects/cts160011p/wehs7661/alchemical_MetaD/System_3/Test_1/rep_3
Command line:
  gmx_mpi mdrun -s sys3.tpr -x sys3_md.xtc -c sys3_output.gro -g md.log -e md.edr -plumed plumed.dat -cpi state.cpt

Reading file sys3.tpr, VERSION 2021.4-plumed-2.8.0 (single precision)
Changing nstlist from 10 to 40, rlist from 0.9 to 1.004

Using 128 MPI processes

Non-default thread affinity set, disabling internal thread affinity

Using 1 OpenMP thread per MPI process

starting mdrun 'Untitled'
50000000 steps, 100000.0 ps.

Writing final coordinates.


Dynamic load balancing report:
 DLB got disabled because it was unsuitable to use.
 Average load imbalance: 23.8%.
 The balanceable part of the MD step is 60%, load imbalance is computed from this.
 Part of the total run time spent waiting due to load imbalance: 14.2%.
 Average PME mesh/force load: 0.144
 Part of the total run time spent waiting due to PP/PME imbalance: 33.6 %

NOTE: 14.2 % of the available CPU time was lost due to load imbalance
      in the domain decomposition.
      You can consider manually changing the decomposition (option -dd);
      e.g. by using fewer domains along the box dimension in which there is
      considerable inhomogeneity in the simulated system.
NOTE: 33.6 % performance was lost because the PME ranks
      had less work to do than the PP ranks.
      You might want to decrease the number of PME ranks
      or decrease the cut-off and the grid spacing.


               Core t (s)   Wall t (s)        (%)
       Time: 21543540.227   168308.933    12800.0
                         1d22h45:08
                 (ns/day)    (hour/ns)
Performance:       51.334        0.468

GROMACS reminds you: "Our hands are tied by physics." (Christian Blau)

